{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1.1, Implementing Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test parameters\n",
    "\n",
    "u_test = np.array([10,10])\n",
    "cov_test = np.array([10,0,0,10]).reshape([2,2])\n",
    "A_test = np.array([10,5,5,10]).reshape([2,2])\n",
    "b_test = np.array([400,400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Objective funtions and gradients\n",
    "\n",
    "#test objective function, vectorized input\n",
    "    #mean: vector of means of input vars\n",
    "    #cov: covariance matrix of input vars\n",
    "    #x: vector of inputs\n",
    "#returns scalar output\n",
    "def gaussian_objective(u, cov, x):\n",
    "    return -np.power(10,4) / (np.sqrt(np.power(2*np.pi,len(u))*np.linalg.det(cov))) *np.exp(-0.5 * np.dot(np.dot(np.subtract(x,u),np.linalg.inv(cov)), np.subtract(x,u)))\n",
    "    \n",
    "def gaussian_gradient(u, cov, x):\n",
    "    return -1*gaussian_objective(u,cov,x)*np.linalg.inv(cov)*np.subtract(x,u)\n",
    "\n",
    "#quadratic objective function\n",
    "    #A: positive definite matrix\n",
    "    #b: vector\n",
    "def quadratic_objective(A,b,x):\n",
    "    return 0.5 * np.subtract(np.dot(np.dot(x,A),x),np.dot(x,b))\n",
    "\n",
    "def quadratic_gradient(A,b,x):\n",
    "    return np.subtract(np.dot(A,x),b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#gradient descent\n",
    "\n",
    "def run_gradient_descent(func, deriv, x0, h, tol):\n",
    "    x = []\n",
    "    d = []\n",
    "    f = []\n",
    "    while 1:\n",
    "        dx0 = deriv(x0)\n",
    "        x.append(x0)\n",
    "        d.append(dx0)\n",
    "        \n",
    "        x1 = x0 - h*dx0\n",
    "        fx1 = func(x1)\n",
    "        fx0 = func(x0)\n",
    "        f.append(fx0)\n",
    "        if np.all(abs(fx1-fx0) < tol):\n",
    "            x.append(x1)\n",
    "            f.append(fx1)\n",
    "            break\n",
    "        x0 = x1\n",
    "    return x, d, f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([10, 10]),\n",
       "  array([ 35.,  35.]),\n",
       "  array([ 22.5,  22.5]),\n",
       "  array([ 28.75,  28.75]),\n",
       "  array([ 25.625,  25.625]),\n",
       "  array([ 27.1875,  27.1875]),\n",
       "  array([ 26.40625,  26.40625]),\n",
       "  array([ 26.796875,  26.796875]),\n",
       "  array([ 26.6015625,  26.6015625]),\n",
       "  array([ 26.69921875,  26.69921875]),\n",
       "  array([ 26.65039062,  26.65039062]),\n",
       "  array([ 26.67480469,  26.67480469]),\n",
       "  array([ 26.66259766,  26.66259766]),\n",
       "  array([ 26.66870117,  26.66870117]),\n",
       "  array([ 26.66564941,  26.66564941]),\n",
       "  array([ 26.66717529,  26.66717529]),\n",
       "  array([ 26.66641235,  26.66641235]),\n",
       "  array([ 26.66679382,  26.66679382]),\n",
       "  array([ 26.66660309,  26.66660309]),\n",
       "  array([ 26.66669846,  26.66669846]),\n",
       "  array([ 26.66665077,  26.66665077]),\n",
       "  array([ 26.66667461,  26.66667461]),\n",
       "  array([ 26.66666269,  26.66666269]),\n",
       "  array([ 26.66666865,  26.66666865]),\n",
       "  array([ 26.66666567,  26.66666567]),\n",
       "  array([ 26.66666716,  26.66666716])],\n",
       " [array([-250, -250]),\n",
       "  array([ 125.,  125.]),\n",
       "  array([-62.5, -62.5]),\n",
       "  array([ 31.25,  31.25]),\n",
       "  array([-15.625, -15.625]),\n",
       "  array([ 7.8125,  7.8125]),\n",
       "  array([-3.90625, -3.90625]),\n",
       "  array([ 1.953125,  1.953125]),\n",
       "  array([-0.9765625, -0.9765625]),\n",
       "  array([ 0.48828125,  0.48828125]),\n",
       "  array([-0.24414062, -0.24414062]),\n",
       "  array([ 0.12207031,  0.12207031]),\n",
       "  array([-0.06103516, -0.06103516]),\n",
       "  array([ 0.03051758,  0.03051758]),\n",
       "  array([-0.01525879, -0.01525879]),\n",
       "  array([ 0.00762939,  0.00762939]),\n",
       "  array([-0.0038147, -0.0038147]),\n",
       "  array([ 0.00190735,  0.00190735]),\n",
       "  array([-0.00095367, -0.00095367]),\n",
       "  array([ 0.00047684,  0.00047684]),\n",
       "  array([-0.00023842, -0.00023842]),\n",
       "  array([ 0.00011921,  0.00011921]),\n",
       "  array([ -5.96046448e-05,  -5.96046448e-05]),\n",
       "  array([  2.98023224e-05,   2.98023224e-05]),\n",
       "  array([ -1.49011612e-05,  -1.49011612e-05])],\n",
       " [array([ 950.,  950.]),\n",
       "  array([ 12075.,  12075.]),\n",
       "  array([ 4950.,  4950.]),\n",
       "  array([ 8121.875,  8121.875]),\n",
       "  array([ 6438.28125,  6438.28125]),\n",
       "  array([ 7255.6640625,  7255.6640625]),\n",
       "  array([ 6840.86914062,  6840.86914062]),\n",
       "  array([ 7046.74072266,  7046.74072266]),\n",
       "  array([ 6943.42346191,  6943.42346191]),\n",
       "  array([ 6994.98672485,  6994.98672485]),\n",
       "  array([ 6969.18125153,  6969.18125153]),\n",
       "  array([ 6982.07802773,  6982.07802773]),\n",
       "  array([ 6975.62814951,  6975.62814951]),\n",
       "  array([ 6978.85271609,  6978.85271609]),\n",
       "  array([ 6977.24033967,  6977.24033967]),\n",
       "  array([ 6978.04650459,  6978.04650459]),\n",
       "  array([ 6977.64341631,  6977.64341631]),\n",
       "  array([ 6977.844959,  6977.844959]),\n",
       "  array([ 6977.74418729,  6977.74418729]),\n",
       "  array([ 6977.79457305,  6977.79457305]),\n",
       "  array([ 6977.76938015,  6977.76938015]),\n",
       "  array([ 6977.78197659,  6977.78197659]),\n",
       "  array([ 6977.77567837,  6977.77567837]),\n",
       "  array([ 6977.77882748,  6977.77882748]),\n",
       "  array([ 6977.77725293,  6977.77725293]),\n",
       "  array([ 6977.7780402,  6977.7780402])])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_gradient_descent(lambda x: quadratic_objective(u_test, cov_test, x) ,lambda x: quadratic_gradient(A_test,b_test, x), np.array([10,10]), .1, .001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([10,\n",
       "  8.0,\n",
       "  6.4,\n",
       "  5.12,\n",
       "  4.096,\n",
       "  3.2768,\n",
       "  2.62144,\n",
       "  2.0971520000000003,\n",
       "  1.6777216000000004,\n",
       "  1.3421772800000003,\n",
       "  1.0737418240000003,\n",
       "  0.8589934592000003,\n",
       "  0.6871947673600002,\n",
       "  0.5497558138880001,\n",
       "  0.43980465111040007,\n",
       "  0.35184372088832006,\n",
       "  0.281474976710656,\n",
       "  0.22517998136852482,\n",
       "  0.18014398509481985,\n",
       "  0.14411518807585588,\n",
       "  0.11529215046068471,\n",
       "  0.09223372036854777,\n",
       "  0.07378697629483821,\n",
       "  0.05902958103587057,\n",
       "  0.04722366482869646,\n",
       "  0.037778931862957166],\n",
       " [20,\n",
       "  16.0,\n",
       "  12.8,\n",
       "  10.24,\n",
       "  8.192,\n",
       "  6.5536,\n",
       "  5.24288,\n",
       "  4.194304000000001,\n",
       "  3.3554432000000007,\n",
       "  2.6843545600000005,\n",
       "  2.1474836480000006,\n",
       "  1.7179869184000005,\n",
       "  1.3743895347200004,\n",
       "  1.0995116277760002,\n",
       "  0.8796093022208001,\n",
       "  0.7036874417766401,\n",
       "  0.562949953421312,\n",
       "  0.45035996273704965,\n",
       "  0.3602879701896397,\n",
       "  0.28823037615171176,\n",
       "  0.23058430092136942,\n",
       "  0.18446744073709553,\n",
       "  0.14757395258967643,\n",
       "  0.11805916207174114,\n",
       "  0.09444732965739291],\n",
       " [100,\n",
       "  64.0,\n",
       "  40.96000000000001,\n",
       "  26.2144,\n",
       "  16.777216,\n",
       "  10.73741824,\n",
       "  6.871947673600001,\n",
       "  4.398046511104002,\n",
       "  2.8147497671065613,\n",
       "  1.801439850948199,\n",
       "  1.1529215046068475,\n",
       "  0.7378697629483825,\n",
       "  0.47223664828696477,\n",
       "  0.3022314549036574,\n",
       "  0.19342813113834073,\n",
       "  0.12379400392853807,\n",
       "  0.07922816251426434,\n",
       "  0.050706024009129186,\n",
       "  0.03245185536584268,\n",
       "  0.020769187434139313,\n",
       "  0.013292279957849162,\n",
       "  0.008507059173023463,\n",
       "  0.0054445178707350165,\n",
       "  0.00348449143727041,\n",
       "  0.002230074519853063,\n",
       "  0.0014272476927059603])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_gradient_descent(lambda x: x**2 ,lambda x: 2*x, 10, .1, .001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def central_difference(func, step,x):\n",
    "    return (func(x+0.5*step) - func(x-0.5*step))/step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_objective(theta, X, Y):\n",
    "    return np.sum((np.dot(X,theta) - Y)**2)\n",
    "\n",
    "def batch_gradient(theta, X, Y):\n",
    "    return (2*np.dot(X.T,np.dot(X,theta)-Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,3) and (2,) not aligned: 3 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b09c3481e41e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtestTheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mbatch_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestTheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mbatch_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestTheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-585638b1e12d>\u001b[0m in \u001b[0;36mbatch_objective\u001b[0;34m(theta, X, Y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbatch_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbatch_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (2,3) and (2,) not aligned: 3 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "m= 2\n",
    "p = 3\n",
    "testX = np.arange(m*p).reshape([m,p])\n",
    "testY = np.arange(p)\n",
    "testTheta = np.ones(m)\n",
    "\n",
    "print batch_objective(testTheta,testX,testY)\n",
    "print batch_gradient(testTheta,testX,testY)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/fittingdatap1_x.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-53ccb250f67b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mX_fitting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_fitting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-53ccb250f67b>\u001b[0m in \u001b[0;36mgetData\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Each corresponding row for X and y represents a single data sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/fittingdatap1_x.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/fittingdatap1_y.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/davekummerlowe/anaconda/lib/python2.7/site-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin)\u001b[0m\n\u001b[1;32m    801\u001b[0m                 \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m                 \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'U'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m                 \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/fittingdatap1_x.txt'"
     ]
    }
   ],
   "source": [
    "import pylab as pl\n",
    "\n",
    "def getData():\n",
    "    \n",
    "    # load the fitting data for X and y and return as elements of a tuple\n",
    "    # X is a 100 by 10 matrix and y is a vector of length 100\n",
    "    # Each corresponding row for X and y represents a single data sample\n",
    "\n",
    "    X = pl.loadtxt('data/fittingdatap1_x.txt')\n",
    "    y = pl.loadtxt('data/fittingdatap1_y.txt', ndmin=2)\n",
    "\n",
    "    return (X,y) \n",
    "\n",
    "X_fitting, Y_fitting = getData();\n",
    "\n",
    "\n",
    "print np.shape(X_fitting)\n",
    "print np.shape(Y_fitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'X_fitting' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7874e495d884>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_fitting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_fitting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_fitting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_fitting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.000001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-303dbd685848>\u001b[0m in \u001b[0;36mrun_gradient_descent\u001b[0;34m(func, deriv, x0, h, tol)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mdx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-7874e495d884>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(theta)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_fitting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_fitting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_fitting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_fitting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.000001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'X_fitting' is not defined"
     ]
    }
   ],
   "source": [
    "results = run_gradient_descent(lambda theta: batch_objective(theta, X_fitting, Y_fitting),lambda theta: batch_gradient(theta, X_fitting, Y_fitting), np.zeros((10,1)),0.000001,.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_fitting' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-84ea05515998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fitting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_fitting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_fitting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_fitting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mw_opt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mbatch_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_fitting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_fitting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mbatch_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_opt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_fitting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_fitting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_fitting' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "w_opt = np.dot(np.dot(np.linalg.inv(np.dot(X_fitting.T,X_fitting)), X_fitting.T), Y_fitting)\n",
    "print w_opt\n",
    "print batch_objective(w_opt, X_fitting, Y_fitting)\n",
    "print batch_gradient(w_opt,X_fitting, Y_fitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w_opt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5f7f82b180ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_fitting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_fitting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_fitting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_fitting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_opt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'w_opt' is not defined"
     ]
    }
   ],
   "source": [
    "results_opt = run_gradient_descent(lambda theta: batch_objective(theta, X_fitting, Y_fitting),lambda theta: batch_gradient(theta, X_fitting, Y_fitting), w_opt,0.001,.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.50712932e-03]\n",
      " [ -1.26490924e-03]\n",
      " [  1.59659337e-03]\n",
      " [ -1.15665882e-03]\n",
      " [ -4.48456272e-04]\n",
      " [ -2.77008092e-03]\n",
      " [ -4.97742454e-03]\n",
      " [ -9.35992122e-04]\n",
      " [  7.56091429e-04]\n",
      " [ -2.21866974e-05]]\n"
     ]
    }
   ],
   "source": [
    "print results[0][-1] - w_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "def stochastic_gradient_descent(func, deriv, X, Y, theta0, tau, k, tol):\n",
    "    ndata = np.shape(X)[0]\n",
    "    nparams = np.shape(theta0)[0]\n",
    "    t = 0\n",
    "    #theta_list = []\n",
    "    err = []\n",
    "    while 1:\n",
    "        order = range(ndata)\n",
    "        np.random.shuffle(order)\n",
    "        theta0_copy = theta0.copy()\n",
    "        for i in order:\n",
    "            xx = X[i,:].reshape((1,nparams))\n",
    "            yy = Y[i].reshape((1,1))\n",
    "            step = (tau+t)**(-k)\n",
    "            d = deriv(theta0,xx,yy)\n",
    "            theta1 = theta0-step*d\n",
    "            theta0 = theta1\n",
    "            t += 1\n",
    "            if t > 100000:\n",
    "                print err[-10:]\n",
    "                raise RuntimeError\n",
    "        fx1 = func(theta1,X,Y)\n",
    "        fx0 = func(theta0_copy,X,Y)\n",
    "        err.append(abs(fx1-fx0))\n",
    "        if abs(fx1-fx0) < tol:\n",
    "            break\n",
    "    return theta1, t\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.15024152e-04]\n",
      " [  1.04394983e-05]\n",
      " [  1.47746580e-06]\n",
      " [  2.79191777e-04]\n",
      " [ -3.61444338e-05]\n",
      " [ -5.58645657e-05]\n",
      " [  8.58793248e-05]\n",
      " [  1.43709151e-04]\n",
      " [  8.93007580e-05]\n",
      " [  1.35898169e-04]]\n"
     ]
    }
   ],
   "source": [
    "results_sgd = stochastic_gradient_descent(batch_objective,batch_gradient, X_fitting, Y_fitting, w_opt, 100000000.,.75,.1)\n",
    "print results_sgd-w_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.16227766017e-05\n",
      "3.16227528846e-05\n",
      "3.16227291676e-05\n",
      "3.16227054506e-05\n",
      "3.16226817337e-05\n",
      "3.16226580168e-05\n",
      "3.16226342999e-05\n",
      "3.16226105831e-05\n",
      "3.16225868664e-05\n",
      "3.16225631496e-05\n"
     ]
    }
   ],
   "source": [
    "tau = 1000000\n",
    "k = .75\n",
    "t = 0\n",
    "for i in range(10):\n",
    "    print (t+tau)**(-k)\n",
    "    t += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.33944892e-03]\n",
      " [ -1.47637471e-03]\n",
      " [  1.85975256e-03]\n",
      " [ -1.38911654e-03]\n",
      " [ -4.16107113e-04]\n",
      " [ -3.05058698e-03]\n",
      " [ -5.78215266e-03]\n",
      " [ -1.27045697e-03]\n",
      " [  7.16496296e-04]\n",
      " [ -6.45513866e-05]]\n"
     ]
    }
   ],
   "source": [
    "results_sgd = stochastic_gradient_descent(batch_objective,batch_gradient, X_fitting, Y_fitting, np.zeros((10,1)), 100000000.,.75,.1)\n",
    "print results_sgd-w_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEPCAYAAABsj5JaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRgwQSVIjBogkqREDRJLUiAEiSWrk/wMoo4KfhCZC7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c6d9390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "\n",
    "def getData(ifPlotData=True):\n",
    "    # load the fitting data and (optionally) plot out for examination\n",
    "    # return the X and Y as a tuple\n",
    "\n",
    "    data = pl.loadtxt('data/curvefittingp2.txt')\n",
    "\n",
    "    X = data[0,:]\n",
    "    Y = data[1,:]\n",
    "\n",
    "    if ifPlotData:\n",
    "        plt.plot(X,Y,'o')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.show()\n",
    "\n",
    "    return (X,Y)\n",
    "\n",
    "X, Y = getData()\n",
    "X = X.reshape((11,1))\n",
    "Y = Y.reshape((11,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. ]\n",
      " [ 0.1]\n",
      " [ 0.2]\n",
      " [ 0.3]\n",
      " [ 0.4]\n",
      " [ 0.5]\n",
      " [ 0.6]\n",
      " [ 0.7]\n",
      " [ 0.8]\n",
      " [ 0.9]\n",
      " [ 1. ]]\n"
     ]
    }
   ],
   "source": [
    "print X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_polynomial(X, Y, M, out_png=None):\n",
    "    '''Problem 2.1'''\n",
    "    # TODO: replace with our implementation\n",
    "    #z = np.polyfit(X, Y, M)\n",
    "\n",
    "    assert len(np.shape(X)) == 1\n",
    "    A = np.empty((len(X),M+1))\n",
    "    for i in range(M+1):\n",
    "        A[:,i] = X**i\n",
    "    A = np.matrix(A)\n",
    "    Y = np.matrix(Y).T # Nx1 matrix\n",
    "    weights = np.linalg.inv(A.T*A)*A.T*Y\n",
    "    weights = np.reshape(np.array(weights),M+1) # back to np array\n",
    "\n",
    "    if out_png:\n",
    "        plt.figure(1)\n",
    "        plt.clf()\n",
    "        plt.plot(X,np.array(Y),'o',color='blue')\n",
    "\n",
    "        xp = np.linspace(0, 1, 100)\n",
    "        y_model = np.cos(np.pi*xp) + 1.5*np.cos(2*np.pi*xp)\n",
    "        plt.plot(xp, y_model, color='yellow')\n",
    "\n",
    "        #def polynomial(xx):\n",
    "        #    yy = 0\n",
    "        #    for ii in range(M+1):\n",
    "        #        w = weights.item((ii, 0))\n",
    "        #        yy += w*xx**ii\n",
    "        #    return yy\n",
    "\n",
    "        y_regress = [polynomial(xx, weights) for xx in xp]\n",
    "        #poly = np.poly1d(z)\n",
    "        #y_regress = map(poly, xp)\n",
    "        plt.plot(xp, y_regress, color='red')\n",
    "\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.title('Linear Regression (M={})'.format(M))\n",
    "\n",
    "        plt.savefig(out_png)\n",
    "    return weights\n",
    "\n",
    "def polynomial(x,weights):\n",
    "    assert len(np.shape(weights)) == 1\n",
    "    yy = [w*x**ii for ii, w in enumerate(weights)]\n",
    "    return np.sum(yy)\n",
    "\n",
    "def compute_SSE(X, Y, M, weights):\n",
    "    '''Problem 2.2'''\n",
    "    A = np.empty((len(X),M+1))\n",
    "    for i in range(M+1):\n",
    "        A[:,i] = X**i\n",
    "    \n",
    "    SSE = batch_objective(weights, A,Y)\n",
    "    deriv = batch_gradient(weights, A, Y)\n",
    "    \n",
    "    return SSE, deriv\n",
    "\n",
    "def central_difference(func, step, x):\n",
    "    return (func(x+0.5*step) - func(x-0.5*step))/step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights\n",
      "[-0.00087273]\n",
      "(13.476960001818181, array([  7.77156117e-16]))\n",
      "weights\n",
      "[ 0.90554091 -1.81282727]\n",
      "(9.8619830090000011, array([  6.66133815e-15,   3.55271368e-15]))\n",
      "weights\n",
      "[  2.36687552 -10.73144911   6.61648601   2.48074981]\n",
      "(0.65484574996503397, array([  6.35602682e-13,   4.05508960e-13,   3.29458683e-13,\n",
      "         2.78388423e-13]))\n",
      "weights\n",
      "[  2.27370190e+00  -6.17646429e+01   1.97787467e+03  -2.73023028e+04\n",
      "   1.89367641e+05  -7.49292026e+05   1.79592248e+06  -2.65353092e+06\n",
      "   2.36176881e+06  -1.16080874e+06   2.41957508e+05]\n",
      "(0.00058268739273887357, array([-0.09494442, -0.05506849, -0.03924035, -0.03067857, -0.0253377 ,\n",
      "       -0.02170731, -0.01909475, -0.01713652, -0.01562323, -0.01442568,\n",
      "       -0.01345988]))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiJSyP8DpjPzpjy3nkAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c48ead0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, Y = getData(False)\n",
    "for M in (0,1,3,10):\n",
    "    weights = fit_polynomial(X,Y,M,'regress_m_%i.png' % M)\n",
    "    print \"weights\"\n",
    "    print weights\n",
    "    print compute_SSE(X,Y,M,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = 1\n",
    "\n",
    "def compute_only_SSE(X_, Y, M, weights):\n",
    "    X = X_.reshape(11)\n",
    "    A = np.empty((len(X),M+1))\n",
    "    for i in range(M+1):\n",
    "        A[:,i] = X**i\n",
    "    SSE = batch_objective(weights, A,Y)\n",
    "    return SSE\n",
    "\n",
    "def compute_only_deriv(X_, Y, M, weights):\n",
    "    X = X_.reshape(11)\n",
    "    A = np.empty((len(X),M+1))\n",
    "    for i in range(M+1):\n",
    "        A[:,i] = X**i\n",
    "    deriv = batch_gradient(weights, A,Y)\n",
    "    return deriv\n",
    "\n",
    "poly_grad_des = run_gradient_descent(lambda w: compute_only_SSE(X, Y,M,w),lambda w: compute_only_deriv(X, Y,M,w),np.zeros((M+1,1)),0.001,0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.87804619]\n",
      " [-1.76216315]]\n"
     ]
    }
   ],
   "source": [
    "print poly_grad_des[0][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X.reshape(11)\n",
    "A = np.empty((len(X),M+1))\n",
    "for i in range(M+1):\n",
    "    A[:,i] = X**i\n",
    "'''\n",
    "def compute_only_SSE(weights, X_, Y):\n",
    "    M = len(weights)\n",
    "    X = X_.reshape(11)\n",
    "    A = np.empty((len(X),M+1))\n",
    "    for i in range(M+1):\n",
    "        A[:,i] = X**i\n",
    "    SSE = batch_objective(weights, A,Y)\n",
    "    return SSE\n",
    "\n",
    "def compute_only_deriv(weights, X_, Y):\n",
    "    M = len(weights)\n",
    "    X = X_.reshape(11)\n",
    "    A = np.empty((len(X),M+1))\n",
    "    for i in range(M+1):\n",
    "        A[:,i] = X**i\n",
    "    deriv = batch_gradient(weights, A,Y)\n",
    "    return deriv\n",
    "\n",
    "'''    \n",
    "M=1\n",
    "poly_sgd = stochastic_gradient_descent(batch_objective, batch_gradient, A, Y, np.zeros((M+1,1)),100.,.75,.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.84636832],\n",
      "       [-1.7019844 ]]), 3179)\n"
     ]
    }
   ],
   "source": [
    "print poly_sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_weights(X, Y,M, lamb):\n",
    "    return np.dot(np.dot(np.linalg.inv(np.add(lamb*np.identity(M+1),np.dot(X.T,X))),X.T),Y)\n",
    "\n",
    "def polynomial(x,weights):\n",
    "    assert len(np.shape(weights)) == 1\n",
    "    yy = [w*x**ii for ii, w in enumerate(weights)]\n",
    "    return np.sum(yy)\n",
    "\n",
    "def fit_polynomial_ridge(X, Y, M, lamb, out_png=None):\n",
    "\n",
    "    assert len(np.shape(X)) == 1\n",
    "    A = np.empty((len(X),M+1))\n",
    "    for i in range(M+1):\n",
    "        A[:,i] = X**i\n",
    "    #A = np.matrix(A)\n",
    "    #Y = np.matrix(Y).T # Nx1 matrix\n",
    "    weights = ridge_weights(A,Y,M,lamb)\n",
    "    #weights = np.reshape(np.array(weights),M+1) # back to np array\n",
    "\n",
    "    if out_png:\n",
    "        plt.figure(1)\n",
    "        plt.clf()\n",
    "        plt.plot(X,np.array(Y),'o',color='blue')\n",
    "\n",
    "        xp = np.linspace(0, 1, 100)\n",
    "        y_model = np.cos(np.pi*xp) + 1.5*np.cos(2*np.pi*xp)\n",
    "        plt.plot(xp, y_model, color='yellow')\n",
    "\n",
    "        y_regress = [polynomial(xx, weights) for xx in xp]\n",
    "        plt.plot(xp, y_regress, color='red')\n",
    "\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.title('Ridge Regression (M={})'.format(M))\n",
    "\n",
    "        plt.savefig(out_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b83b2b6714c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#weigths = fit_polynomial_ridge(X,Y,3,0.001,out_png = 'test_ridge.png')#,'ridge_m_%i.png' % M)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mM\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlamb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mii\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_polynomial_ridge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ridge_plots/ridge_m_%i_lambda_%s.png'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlamb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getData' is not defined"
     ]
    }
   ],
   "source": [
    "X, Y = getData(False)\n",
    "#weigths = fit_polynomial_ridge(X,Y,3,0.001,out_png = 'test_ridge.png')#,'ridge_m_%i.png' % M)\n",
    "for M in (0,1,3,10):\n",
    "    for lamb in [10**ii for ii in range(-3,4)]:\n",
    "        weights = fit_polynomial_ridge(X,Y,M,lamb,'ridge_plots/ridge_m_%i_lambda_%s.png' % (M,lamb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
